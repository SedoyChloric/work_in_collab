{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SedoyChloric/work_in_collab/blob/test/MiniSOM_Clusterisation%2013%2C04%2C25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6saWGgs0h_R6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6751e920-534d-4954-9de5-65841f9ab535"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting minisom==2.3.5\n",
            "  Downloading minisom-2.3.5.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: minisom\n",
            "  Building wheel for minisom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minisom: filename=MiniSom-2.3.5-py3-none-any.whl size=12031 sha256=e4e08178fe52abce027ab70d6733c180e823693c13a3cf4ef3eaa4ec84922385\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/db/95/5e53bc2b88a328217fdf9f2886cafbe86b0df274f4b601f572\n",
            "Successfully built minisom\n",
            "Installing collected packages: minisom\n",
            "Successfully installed minisom-2.3.5\n"
          ]
        }
      ],
      "source": [
        "from IPython import get_ipython\n",
        "get_ipython().system('pip install minisom==2.3.5')\n",
        "import matplotlib.pyplot as plt\n",
        "from minisom import MiniSom\n",
        "import numpy as np\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from pylab import plot,axis,show,pcolor,colorbar,bone\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "clusterisation_column = 8\n",
        "idk = \"Я не знаю таких цифр\""
      ],
      "metadata": {
        "id": "8x2jgW6vD3Ea"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "f_SxRRZkh0nb"
      },
      "outputs": [],
      "source": [
        "def get_data_from_googlesheet(google_spreedsheet, sheet_name):\n",
        "  table = np.array(google_spreedsheet.worksheet(sheet_name).get_all_values()) #Лист преобразуется в массив\n",
        "  name_of_properties = table[0][3:-1] # Получаем наименования свойств (со второго до предпоследнего)\n",
        "  table = np.transpose(table) #Транспонируем\n",
        "  id = table[1][1:] #Получаем лист наименований\n",
        "  source = table[-1][1:] #Получаем лист сурсов\n",
        "  properties = table[3:-1][0:] #Получаем лист свойств, который нужно будет снова транспонировать\n",
        "  return id, source, np.transpose(np.delete(properties, 0, 1).astype('float64')), name_of_properties\n",
        "\n",
        "def to_normalize_except_material(array):\n",
        "  min_val = np.min(array[:, 1:])\n",
        "  max_val = np.max(array[:, 1:])\n",
        "  normed_array = (array[:, 1:] - min_val) / (max_val - min_val)\n",
        "  return np.column_stack((array[:, 0], normed_array))\n",
        "\n",
        "def to_normalize_by_row(array):\n",
        "  normed_array = np.zeros(array.shape)\n",
        "  for i in range(len(array)):\n",
        "    min_val = np.min(array[i])\n",
        "    max_val = np.max(array[i])\n",
        "    normed_array[i] = array[i]\n",
        "    normed_array[i] = (array[i] - min_val) / (max_val - min_val)\n",
        "  return normed_array\n",
        "\n",
        "def add_neighbors(data, point_index, eps):\n",
        "  neighbors = np.array([])\n",
        "  for i in range(len(data)):\n",
        "    if np.linalg.norm(data[i]-data[point_index]) <= eps:\n",
        "      neighbors = np.append(neighbors, i)\n",
        "  return neighbors.astype('int32')\n",
        "\n",
        "def release_dbscan(data, eps, min_points):\n",
        "  cluster_id = 0\n",
        "  labels = np.zeros(len(data), dtype='int32')\n",
        "  for point in range(len(data)):\n",
        "    if labels[point] != 0:\n",
        "      continue\n",
        "    neighbors = add_neighbors(data, point, eps)\n",
        "    if len(neighbors) < min_points:\n",
        "      labels[point] = -1\n",
        "      continue\n",
        "    labels[point] = cluster_id + 1\n",
        "    seed = neighbors\n",
        "    while len(seed) > 0:\n",
        "      current_point = seed[0]\n",
        "      seed = np.delete(seed, 0)\n",
        "      if labels[current_point] == -1:\n",
        "        labels[current_point] = cluster_id +1\n",
        "      if labels[current_point] != 0:\n",
        "        continue\n",
        "      labels[current_point] = cluster_id + 1\n",
        "      new_neighbors = add_neighbors(data, current_point, eps)\n",
        "      if len(new_neighbors) >= min_points:\n",
        "        seed = np.append(seed, new_neighbors)\n",
        "    cluster_id += 1\n",
        "  return labels\n",
        "\n",
        "def calculate_column(number, alphabet=alphabet):\n",
        "  column = ''\n",
        "  while number > 0:\n",
        "    number, remainder = divmod(number - 1, 26)\n",
        "    column = alphabet[remainder] + column\n",
        "  return column\n",
        "\n",
        "def to_list(array):\n",
        "  return array.reshape(-1, 1).tolist()\n",
        "\n",
        "def prepare_clusters(winner_coordinates, learning_rate, sigma, iterations, column, frequency_threshold):\n",
        "  col = calculate_column(column)\n",
        "  title = np.array([[np.round(learning_rate, 4), np.round(sigma, 4), iterations, f'=COUNTUNIQUE({col}6:{col})', f'=\"№\"&столбец({col}1)-7']])\n",
        "  unique_coords, cluster_labels, labels_frequency = np.unique(winner_coordinates, axis=0, return_inverse=True, return_counts=True)\n",
        "  for i, freq in enumerate(labels_frequency):\n",
        "    if freq < frequency_threshold:\n",
        "      cluster_labels[cluster_labels == i] = -1\n",
        "  return np.append(title, [cluster_labels], axis=1)\n",
        "\n",
        "def prepare_googlesheet_for_nd(id_array, source_array, properties_values, name_of_properties, worksheet, row_bias):\n",
        "  worksheet.update(to_list(np.arange(len(id_array)+1)), f'a{row_bias}:a')\n",
        "  worksheet.update(to_list(id_array), f'b{row_bias+1}:b')\n",
        "  worksheet.update([name_of_properties.tolist()], f'c{row_bias}')\n",
        "  worksheet.update(properties_values.tolist(), f'c{row_bias+1}')\n",
        "  worksheet.update_acell(f'b{row_bias}]', \"Наименование точки\")\n",
        "  worksheet.update_acell(f'{calculate_column(len(name_of_properties)+3)}{row_bias}', \"Кластеризация\")\n",
        "  return\n",
        "\n",
        "def prepare_googlesheet_for_1d(id_array, source_array, property_values, name_of_property, worksheet):\n",
        "  worksheet.update(to_list(np.arange(len(id_array)+1)), 'a1:a')\n",
        "  worksheet.update(to_list(id_array), 'b2:b')\n",
        "  worksheet.update(to_list(property_values), 'c2:c')\n",
        "  worksheet.update_acell('b1', name_of_property)\n",
        "  worksheet.update_acell('c1', \"Значение\")\n",
        "  worksheet.update_acell('d1', \"Кластеризация\")\n",
        "  return\n",
        "\n",
        "def import_result_in_googlesheet_neuro(packed_clusters, worksheet, row_bias):\n",
        "  clusterisation = worksheet.find('Кластеризация').col\n",
        "  column = calculate_column(clusterisation)\n",
        "  worksheet.update_acell(f'{calculate_column(clusterisation+len(packed_clusters[0]))}{row_bias}', 'Кластеризация')\n",
        "  worksheet.update(packed_clusters.tolist(), f'{column}{row_bias}', value_input_option='USER_ENTERED')\n",
        "  return\n",
        "\n",
        "def import_result_in_googlesheet_dbscan(packed_clusters, worksheet, radius, minimum_points):\n",
        "  column = worksheet.find('Кластеризация').col\n",
        "  worksheet.update_acell(f'{calculate_column(column)}1', f'R={np.round(radius, 4)}; mp={np.round(minimum_points, 4)}')\n",
        "  worksheet.update_acell(f'{calculate_column(column+1)}1', 'Кластеризация')\n",
        "  worksheet.update(to_list(packed_clusters), f'{calculate_column(column)}2:{calculate_column(column)}')\n",
        "  return\n",
        "\n",
        "def batch_clusterizarion(data, normed_data, start_eps, minimum_points, worksheet):\n",
        "  step = 0.01\n",
        "  end_eps = np.round(start_eps*10, 4)\n",
        "  i = start_eps\n",
        "  while i <= end_eps:\n",
        "    labels = release_dbscan(normed_data, i, minimum_points) ####\n",
        "    packed_clusters = pack_clusters(data, labels, minimum_points)\n",
        "    import_result_in_googlesheet_dbscan(packed_clusters, worksheet, np.round(i, 4), minimum_points)\n",
        "    i += np.round(step, 4)\n",
        "  return\n",
        "\n",
        "def split_array(array, deliminer1, deliminer2):\n",
        "  return array[:deliminer1], array[deliminer1:deliminer2]\n",
        "\n",
        "def trim_table(worksheet, threshold_value, start, end):\n",
        "  unsupervised_data = np.array(worksheet.get_all_values())\n",
        "  data = unsupervised_data[start:end][:].astype('float64')\n",
        "  columns_to_delete = np.zeros(len(data[0]), dtype=bool)\n",
        "  columns_to_delete[data[0] >= threshold_value] = True\n",
        "  columns_to_delete[data[1] >= threshold_value] = True\n",
        "  unsupervised_data = np.delete(unsupervised_data, columns_to_delete, axis=1)\n",
        "  worksheet.clear()\n",
        "  worksheet.update(unsupervised_data.tolist(), f'a1')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(calculate_column(438+1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCjtRiZ1t_R5",
        "outputId": "cc77da1d-9353-42af-9f4f-67724e606f0d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aerogel_spreedsheet = gc.open_by_key('1PMc-dFmc5srbDXqIfrrWNw_HHRrXcHkL5w0bQ5Bb1HU')\n",
        "experiment_spreadsheet = gc.open_by_key('1etXfria78osnRn9U6QjbXlWe2KgljOp7mreyIEdNV9U')\n",
        "id_array, source_array, data, name_of_properties = get_data_from_googlesheet(aerogel_spreedsheet, \"Данные по аэрогелям без вставных данных\")"
      ],
      "metadata": {
        "id": "uSsFae3ioCmP"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_id, test_id = split_array(id_array, 20, 29)\n",
        "test_id = \"*\"+test_id\n",
        "id_array = np.append(train_id, test_id)\n",
        "print(test_id)"
      ],
      "metadata": {
        "id": "lg9p4rDd4S-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2efae17d-a086-4a8d-bfd4-1aae70ec9233"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['*Этанол-муравьиная' '*Альгинат:хлорид кальция 1--1' '*SiO2-0,1-7'\n",
            " '*ИПС-муравьиная' '*Альгинат:хитозан 1:0.50' '*Альгинат:хитозан 1:0.75'\n",
            " '*SiO2-лигносульфонат 60%' '*Гибрид хитозан-лигнин А2'\n",
            " '*SiO2-лигносульфонат 30%']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  sheet_name = input(\"Результаты будут импортированы в гугл-таблицу. \\nИмя листа будет: \")\n",
        "  worksheet = experiment_spreadsheet.add_worksheet(title=sheet_name, rows=len(id_array)+10, cols=2000)\n",
        "  prepare_googlesheet_for_nd(id_array, source_array, data, name_of_properties, worksheet, 5)\n",
        "except gspread.exceptions.APIError:\n",
        "  worksheet = experiment_spreadsheet.worksheet(sheet_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue0LX_Md3eJ3",
        "outputId": "775c47db-df1d-4837-acdd-0a1dc4804807"
      },
      "execution_count": 28,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Результаты будут импортированы в гугл-таблицу. \n",
            "Имя листа будет: test10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normed_data = to_normalize_except_material(data)\n",
        "column = 8\n",
        "for i in range(2, 7):\n",
        "  learning_rate = i*0.1\n",
        "  for j in range(1, 11):\n",
        "    sigma = j*0.2\n",
        "    packed_clusters = np.zeros((1, len(normed_data)+5))\n",
        "    for k in range(12, 18):\n",
        "      iterations = k*50\n",
        "      som = MiniSom(10, 10, len(normed_data[0]), sigma=sigma, learning_rate=learning_rate)\n",
        "      som.train_batch(normed_data, iterations)\n",
        "      winner_coordinates = np.array([som.winner(x) for x in normed_data])\n",
        "      clusterisation_results = prepare_clusters(winner_coordinates, learning_rate, sigma, iterations, column, 3)\n",
        "      packed_clusters = np.append(packed_clusters, clusterisation_results, axis=0)\n",
        "      column +=1\n",
        "    packed_clusters = np.delete(packed_clusters, 0, axis=0)\n",
        "    import_result_in_googlesheet_neuro(packed_clusters.T, worksheet, 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "JcjbDEdmlffY",
        "outputId": "17532ce7-f988-40c6-d36a-f3c310451513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-29166a62ec22>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0msom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMiniSom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0msom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mwinner_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwinner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormed_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mclusterisation_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinner_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/minisom.py\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(self, data, num_iteration, verbose)\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mprinted\u001b[0m \u001b[0mat\u001b[0m \u001b[0meach\u001b[0m \u001b[0mtime\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mweights\u001b[0m \u001b[0mare\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \"\"\"\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdistance_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/minisom.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data, num_iteration, random_order, verbose, use_epochs, fixed_points)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m             \u001b[0mdecay_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_decay_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m             self.update(data[iteration],\n\u001b[0m\u001b[1;32m    524\u001b[0m                         fixed_points.get(iteration,\n\u001b[1;32m    525\u001b[0m                                          self.winner(data[iteration])),\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/minisom.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, x, win, t, max_iteration)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sigma_decay_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# improves the performances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighborhood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;31m# w_new = eta * neighborhood_function * (x-w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ij, ijk->ijk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/minisom.py\u001b[0m in \u001b[0;36m_gaussian\u001b[0;34m(self, c, sigma)\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0may\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_yy\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_yy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0may\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m  \u001b[0;31m# the external product gives a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sigma = 1.6\n",
        "learning_rate = 0.8\n",
        "iterations = 700\n",
        "axiss = np.array([[1, 2], [8 ,5]])\n",
        "asf = np.array([[1, 5], [6, 9]])\n",
        "print(np.append(axiss, asf, axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uq3Kvni5WEJ",
        "outputId": "e254f96c-0d96-4128-cf06-895467e1a5a2"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 1 5]\n",
            " [8 5 6 9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normed_data = to_normalize_except_material(data[:29])\n",
        "train_data, test_data = split_array(normed_data, 20, 29)\n",
        "column = 8\n",
        "for i in range(5, 10):\n",
        "  learning_rate = i*0.1\n",
        "  for j in range(1, 11):\n",
        "    sigma = j*0.2\n",
        "    packed_clusters = np.zeros((1, len(normed_data)+5))\n",
        "    for k in range(12, 18):\n",
        "      iterations = k*50\n",
        "      som = MiniSom(10, 10, len(normed_data[0]), sigma=sigma, learning_rate=learning_rate)\n",
        "      som.train_batch(normed_data, iterations)\n",
        "      winner_coordinates = np.array([som.winner(x) for x in train_data])\n",
        "      winner_coordinates = np.append(winner_coordinates, np.array([som.winner(x) for x in test_data]), axis=0)\n",
        "      clusterisation_results = prepare_clusters(winner_coordinates, learning_rate, sigma, iterations, column, 0)\n",
        "      packed_clusters = np.append(packed_clusters, clusterisation_results, axis=0)\n",
        "      column +=1\n",
        "    packed_clusters = np.delete(packed_clusters, 0, axis=0)\n",
        "    import_result_in_googlesheet_neuro(packed_clusters.T, worksheet, 1)\n"
      ],
      "metadata": {
        "id": "rvY9Pivw6Gu9"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "AuuyBy30sN1w",
        "outputId": "f7d07741-7d3a-4730-a555-27ee6c4febcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Есть на просторах интернета одна гугл-таблица, в которой собрано немного про характеристики аэрогелей.\n",
            "В этой прекрасной гугл-таблице насчитываются характеристики уже 82 аэрогелей\n",
            "Эта программа может разбивать аэрогели на группы при помощи магии, которая зовётся MiniSOM\n",
            "Магия работает по таким характеристикам, как ['Природа' 'Каж. плотность (г/см^3)' 'Уд, поверхность (м^2/г)'\n",
            " 'Диаметр пор (нм)' 'Пористость (%)']\n",
            "1. Кронк, жми на рычаг просмотра данных!\n",
            "2. Кронк, жми на рычаг кластеризации!\n",
            "3. Кронк, жми на рычаг в лабораторию!\n",
            "Нажмите на рычаг: test6\n",
            "Я не знаю таких цифр\n",
            "1. Кронк, жми на рычаг просмотра данных!\n",
            "2. Кронк, жми на рычаг кластеризации!\n",
            "3. Кронк, жми на рычаг в лабораторию!\n",
            "Нажмите на рычаг: 2\n",
            "Результаты будут импортированы в гугл-таблицу. \n",
            "Имя листа будет: test6\n",
            "Задать сигму\n",
            "Одного единого универсального значения нет!\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2dae62d07dc4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m               \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Введите сигму: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m               \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "print(\"Есть на просторах интернета одна гугл-таблица, в которой собрано немного про характеристики аэрогелей.\\n\"\n",
        "  \"В этой прекрасной гугл-таблице насчитываются характеристики уже\", len(id_array), \"аэрогелей\\n\"\n",
        "  \"Эта программа может разбивать аэрогели на группы при помощи магии, которая зовётся MiniSOM\\n\"\n",
        "  \"Магия работает по таким характеристикам, как\", name_of_properties)\n",
        "while True:\n",
        "  print(\"1. Кронк, жми на рычаг просмотра данных!\"\n",
        "  \"\\n2. Кронк, жми на рычаг кластеризации!\"\n",
        "  \"\\n3. Кронк, жми на рычаг в лабораторию!\")\n",
        "  try:\n",
        "    choice = int(input(\"Нажмите на рычаг: \"))\n",
        "    if choice == 1:\n",
        "      for i in range(len(id_array)-1):\n",
        "        print(\"Точка\", id_array[i], \"с координатами:\\n\", data[i])\n",
        "    elif choice == 2:\n",
        "      try:\n",
        "        sheet_name = input(\"Результаты будут импортированы в гугл-таблицу. \\nИмя листа будет: \")\n",
        "        worksheet = experiment_spreadsheet.add_worksheet(title=sheet_name, rows=len(id_array)+5, cols=2000)\n",
        "        prepare_googlesheet_for_nd(id_array, source_array, data, name_of_properties, worksheet)\n",
        "      except gspread.exceptions.APIError:\n",
        "        worksheet = experiment_spreadsheet.worksheet(sheet_name)\n",
        "      while True:\n",
        "        print(\"Задать сигму\\n\"\n",
        "              \"Одного единого универсального значения нет!\\n\")\n",
        "        while True:\n",
        "            try:\n",
        "              sigma = float(input(\"Введите сигму: \"))\n",
        "              break\n",
        "            except ValueError:\n",
        "              print(idk)\n",
        "        print(\"Задать скорость обучения\\n\",\n",
        "              \"1. Использовать 3\\n\",\n",
        "              \"2. Задать число самому\\n\")\n",
        "        choice_2 = input(\"Введите опцию: \")\n",
        "        while True:\n",
        "          if choice_2 == '1':\n",
        "            learning_rate = 0.5\n",
        "            break\n",
        "          elif choice_2 == '2':\n",
        "            while True:\n",
        "              try:\n",
        "                learning_rate = int(input(\"Введите минимальное количество точек (Рекомендуется брать от 5 до 2): \"))\n",
        "                break\n",
        "              except ValueError:\n",
        "                print(idk)\n",
        "          else:\n",
        "            print(idk)\n",
        "        #normed_data = to_normalize_except_material(data)\n",
        "        normed_data = to_normalize_except_material(data)\n",
        "        som = MiniSom(1, len(normed_data[:]), len(normed_data[0, :]), sigma=sigma, learning_rate=learning_rate)\n",
        "        som.train_batch(normed_data, 100)\n",
        "        winner_coordinates = np.array([som.winner(x) for x in data]).T\n",
        "        packed_clusters = pack_clusters(data, winner_coordinates[1], 3)\n",
        "        import_result_in_googlesheet_neuro(packed_clusters, worksheet, sigma, learning_rate)\n",
        "        print(f\"Данные в гугл-таблице на листе '{sheet_name}' обновлены!\\n\")\n",
        "        while True:\n",
        "          print(\"Попробовать изменить радиус и/или минамальное количество точек и попробовать снова?\\n\"\n",
        "          \"1. Да\\n\"\n",
        "          \"2. Нет\\n\")\n",
        "          choice_2 = input(\"Введите опцию: \")\n",
        "          if choice_2 == '1':\n",
        "            break\n",
        "          elif choice_2 == '2':\n",
        "            break\n",
        "          else:\n",
        "            print(idk)\n",
        "        if choice_2 == '2':\n",
        "            break\n",
        "    elif choice == 3:\n",
        "      print(\"ДРУГОЙ РЫЧАААГ\")\n",
        "      break\n",
        "    else:\n",
        "      print(idk)\n",
        "  except ValueError:\n",
        "    print(idk)"
      ]
    },
    {
      "source": [
        "weights = som.get_weights()\n",
        "new_aerogel_data = np.array([1, 2, 3, 4, 5])  # Пример данных 71-го аэрогеля\n",
        "normed_new_aerogel_data = to_normalize_except_material(new_aerogel_data)\n",
        "distances = np.linalg.norm(weights - normed_new_aerogel_data, axis=2)\n",
        "winner_neuron = np.argmin(distances)\n",
        "cluster = winner_neuron  # Предполагается, что кластер соответствует индексу нейрона\n",
        "\n",
        "print(f\"71-й аэрогель относится к кластеру {cluster}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "oUTpvJbsxjDU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}