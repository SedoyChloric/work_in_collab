{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SedoyChloric/work_in_collab/blob/test/MiniSOM_Clusterisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6saWGgs0h_R6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "521d874e-1ae1-4467-aac3-d1b93cbeedce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting minisom==2.3.5\n",
            "  Downloading minisom-2.3.5.tar.gz (12 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: minisom\n",
            "  Building wheel for minisom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minisom: filename=MiniSom-2.3.5-py3-none-any.whl size=12031 sha256=51172d5c03dc9079eda1a46285bb07ada536e1c14febdb4e9430358f0c42161d\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/db/95/5e53bc2b88a328217fdf9f2886cafbe86b0df274f4b601f572\n",
            "Successfully built minisom\n",
            "Installing collected packages: minisom\n",
            "Successfully installed minisom-2.3.5\n"
          ]
        }
      ],
      "source": [
        "from IPython import get_ipython\n",
        "get_ipython().system('pip install minisom==2.3.5')\n",
        "import matplotlib.pyplot as plt\n",
        "from minisom import MiniSom\n",
        "import numpy as np\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from pylab import plot,axis,show,pcolor,colorbar,bone\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "clusterisation_column = 8"
      ],
      "metadata": {
        "id": "8x2jgW6vD3Ea"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "f_SxRRZkh0nb"
      },
      "outputs": [],
      "source": [
        "def get_data_from_googlesheet(google_spreedsheet):\n",
        "  aerogels_properties = np.array(google_spreedsheet.worksheet(\"Данные по аэрогелям\").get_all_values()) #Лист преобразуется в массив\n",
        "  name_of_properties = aerogels_properties[0][3:-1] # Получаем наименования свойств (со второго до предпоследнего)\n",
        "  aerogels_properties = np.transpose(aerogels_properties) #Транспонируем\n",
        "  id = aerogels_properties[1][1:] #Получаем лист наименований\n",
        "  source = aerogels_properties[-1][1:] #Получаем лист сурсов\n",
        "  prop = aerogels_properties[3:-1][0:] #Получаем лист свойств, который нужно будет снова транспонировать\n",
        "  return id, source, np.transpose(np.delete(prop, 0, 1).astype('float64')), name_of_properties\n",
        "\n",
        "def to_normalize_except_material(array):\n",
        "  min_val = np.min(array[:, 1:])\n",
        "  max_val = np.max(array[:, 1:])\n",
        "  normed_array = (array[:, 1:] - min_val) / (max_val - min_val)\n",
        "  return np.column_stack((array[:, 0], normed_array))\n",
        "\n",
        "def add_neighbors(data, point_index, eps):\n",
        "  neighbors = np.array([])\n",
        "  for i in range(len(data)):\n",
        "    if np.linalg.norm(data[i]-data[point_index]) <= eps:\n",
        "      neighbors = np.append(neighbors, i)\n",
        "  return neighbors.astype('int32')\n",
        "\n",
        "def release_dbscan(data, eps, min_points):\n",
        "  cluster_id = 0\n",
        "  labels = np.zeros(len(data), dtype='int32')\n",
        "  for point in range(len(data)):\n",
        "    if labels[point] != 0:\n",
        "      continue\n",
        "    neighbors = add_neighbors(data, point, eps)\n",
        "    if len(neighbors) < min_points:\n",
        "      labels[point] = -1\n",
        "      continue\n",
        "    labels[point] = cluster_id + 1\n",
        "    seed = neighbors\n",
        "    while len(seed) > 0:\n",
        "      current_point = seed[0]\n",
        "      seed = np.delete(seed, 0)\n",
        "      if labels[current_point] == -1:\n",
        "        labels[current_point] = cluster_id +1\n",
        "      if labels[current_point] != 0:\n",
        "        continue\n",
        "      labels[current_point] = cluster_id + 1\n",
        "      new_neighbors = add_neighbors(data, current_point, eps)\n",
        "      if len(new_neighbors) >= min_points:\n",
        "        seed = np.append(seed, new_neighbors)\n",
        "    cluster_id += 1\n",
        "  return labels\n",
        "\n",
        "def calculate_column(number, alphabet=alphabet):\n",
        "  column = ''\n",
        "  while number > 0:\n",
        "    number, remainder = divmod(number - 1, 26)\n",
        "    column = alphabet[remainder] + column\n",
        "  return column\n",
        "\n",
        "def pack_clusters(data, labels, minimum_points):\n",
        "  packed_clusters = labels.astype(str)\n",
        "  cluster_id = 0\n",
        "  packed_clusters[labels == -1] = \"Шум\"\n",
        "  for i in np.unique(labels):\n",
        "    cluster = data[labels == i]\n",
        "    packed_clusters[labels == i] = f\"Кластер №{cluster_id+1}\"\n",
        "    cluster_id +=1\n",
        "  return packed_clusters\n",
        "\n",
        "def to_list(array):\n",
        "  return array.reshape(-1, 1).tolist()\n",
        "\n",
        "def prepare_googlesheet_for_nd(id_array, source_array, property_values, name_of_properties, worksheet):\n",
        "  worksheet.update(to_list(np.arange(len(id_array)+1)), 'a1:a')\n",
        "  worksheet.update(to_list(id_array), 'b2:b')\n",
        "  worksheet.update([name_of_properties.tolist()], 'c1')\n",
        "  worksheet.update(property_values.tolist(), 'c2')\n",
        "  worksheet.update_acell('b1', \"Наименование точки\")\n",
        "  worksheet.update_acell(f'{calculate_column(len(name_of_properties)+3)}1', \"Кластеризация\")\n",
        "  return\n",
        "\n",
        "def prepare_googlesheet_for_1d(id_array, source_array, property_values, name_of_property, worksheet):\n",
        "  worksheet.update(to_list(np.arange(len(id_array)+1)), 'a1:a')\n",
        "  worksheet.update(to_list(id_array), 'b2:b')\n",
        "  worksheet.update(to_list(property_values), 'c2:c')\n",
        "  worksheet.update_acell('b1', name_of_property)\n",
        "  worksheet.update_acell('c1', \"Значение\")\n",
        "  worksheet.update_acell('d1', \"Кластеризация\")\n",
        "  return\n",
        "\n",
        "def import_result_in_googlesheet_neuro(packed_clusters, worksheet, sigma, learning_rate):\n",
        "  column = worksheet.find('Кластеризация').col\n",
        "  worksheet.update_acell(f'{calculate_column(column)}1', f's={np.round(sigma, 4)}; lr={np.round(learning_rate, 4)}')\n",
        "  worksheet.update_acell(f'{calculate_column(column+1)}1', 'Кластеризация')\n",
        "  worksheet.update(to_list(packed_clusters), f'{calculate_column(column)}2:{calculate_column(column)}')\n",
        "  return\n",
        "\n",
        "def import_result_in_googlesheet_dbscan(packed_clusters, worksheet, radius, minimum_points):\n",
        "  column = worksheet.find('Кластеризация').col\n",
        "  worksheet.update_acell(f'{calculate_column(column)}1', f'R={np.round(radius, 4)}; mp={np.round(minimum_points, 4)}')\n",
        "  worksheet.update_acell(f'{calculate_column(column+1)}1', 'Кластеризация')\n",
        "  worksheet.update(to_list(packed_clusters), f'{calculate_column(column)}2:{calculate_column(column)}')\n",
        "  return\n",
        "\n",
        "def batch_clusterizarion(data, normed_data, start_eps, minimum_points, worksheet):\n",
        "  step = 0.01\n",
        "  end_eps = np.round(start_eps*10, 4)\n",
        "  i = start_eps\n",
        "  while i <= end_eps:\n",
        "    labels = release_dbscan(normed_data, i, minimum_points) ####\n",
        "    packed_clusters = pack_clusters(data, labels, minimum_points)\n",
        "    import_result_in_googlesheet_dbscan(packed_clusters, worksheet, np.round(i, 4), minimum_points)\n",
        "    i += np.round(step, 4)\n",
        "  return\n",
        "\n",
        "def reset_clusterisation_column(cc=clusterisation_column):\n",
        "  cc = 8\n",
        "  return\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OIVjnI6kipIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aerogel_spreedsheet = gc.open_by_key('1PMc-dFmc5srbDXqIfrrWNw_HHRrXcHkL5w0bQ5Bb1HU')\n",
        "experiment_spreadsheet = gc.open_by_key('1etXfria78osnRn9U6QjbXlWe2KgljOp7mreyIEdNV9U')\n",
        "id_array, source_array, data, name_of_properties = get_data_from_googlesheet(aerogel_spreedsheet)"
      ],
      "metadata": {
        "id": "uSsFae3ioCmP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normed_data = data.T[0].reshape(-1, 1)\n",
        "learning_rate = 0.5\n",
        "worksheet = experiment_spreadsheet.worksheet(\"test3\")\n",
        "for i in range(4, 5):\n",
        "  learning_rate = i*0.1\n",
        "  for j in range(19, 20):\n",
        "    sigma = 2**(j-10)\n",
        "    som = MiniSom(1, len(normed_data[:]), 1, sigma=sigma, learning_rate=learning_rate)\n",
        "    som.train_batch(normed_data, 100)\n",
        "    winner_coordinates = np.array([som.winner(x) for x in data]).T\n",
        "    packed_clusters = pack_clusters(data, winner_coordinates[1], 3)\n",
        "    import_result_in_googlesheet_neuro(packed_clusters, worksheet, sigma, learning_rate)"
      ],
      "metadata": {
        "id": "rvY9Pivw6Gu9"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuuyBy30sN1w",
        "outputId": "c0a6bc24-2075-4dcb-d062-5f8e7924c257"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Есть на просторах интернета одна гугл-таблица, в которой собрано немного про характеристики аэрогелей.\n",
            "В этой прекрасной гугл-таблице насчитываются характеристики уже 82 аэрогелей\n",
            "Эта программа может разбивать аэрогели на группы при помощи магии, которая зовётся MiniSOM\n",
            "Магия работает по таким характеристикам, как ['Природа' 'Каж. плотность (г/см^3)' 'Уд, поверхность (м^2/г)'\n",
            " 'Диаметр пор (нм)' 'Пористость (%)']\n",
            "1. Кронк, жми на рычаг просмотра данных!\n",
            "2. Кронк, жми на рычаг кластеризации!\n",
            "3. Кронк, жми на рычаг в лабораторию!\n",
            "Нажмите на рычаг: 2\n",
            "Результаты будут импортированы в гугл-таблицу. \n",
            "Имя листа будет: jhgckk\n",
            "Задать сигму\n",
            "Одного единого универсального значения нет!\n",
            "\n",
            "Введите сигму: 0.001\n",
            "Задать скорость обучения\n",
            " 1. Использовать 3\n",
            " 2. Задать число самому\n",
            "\n",
            "Введите опцию: 1\n",
            "Данные в гугл-таблице на листе 'jhgckk' обновлены!\n",
            "\n",
            "Попробовать изменить радиус и/или минамальное количество точек и попробовать снова?\n",
            "1. Да\n",
            "2. Нет\n",
            "\n",
            "Введите опцию: 2\n",
            "1. Кронк, жми на рычаг просмотра данных!\n",
            "2. Кронк, жми на рычаг кластеризации!\n",
            "3. Кронк, жми на рычаг в лабораторию!\n",
            "Нажмите на рычаг: \n",
            "Я не знаю таких цифр\n",
            "1. Кронк, жми на рычаг просмотра данных!\n",
            "2. Кронк, жми на рычаг кластеризации!\n",
            "3. Кронк, жми на рычаг в лабораторию!\n",
            "Нажмите на рычаг: 3\n",
            "ДРУГОЙ РЫЧАААГ\n"
          ]
        }
      ],
      "source": [
        "print(\"Есть на просторах интернета одна гугл-таблица, в которой собрано немного про характеристики аэрогелей.\\n\"\n",
        "  \"В этой прекрасной гугл-таблице насчитываются характеристики уже\", len(id_array), \"аэрогелей\\n\"\n",
        "  \"Эта программа может разбивать аэрогели на группы при помощи магии, которая зовётся MiniSOM\\n\"\n",
        "  \"Магия работает по таким характеристикам, как\", name_of_properties)\n",
        "while True:\n",
        "  print(\"1. Кронк, жми на рычаг просмотра данных!\"\n",
        "  \"\\n2. Кронк, жми на рычаг кластеризации!\"\n",
        "  \"\\n3. Кронк, жми на рычаг в лабораторию!\")\n",
        "  try:\n",
        "    choice = int(input(\"Нажмите на рычаг: \"))\n",
        "    if choice == 1:\n",
        "      for i in range(len(id_array)-1):\n",
        "        print(\"Точка\", id_array[i], \"с координатами:\\n\", data[i])\n",
        "    elif choice == 2:\n",
        "      try:\n",
        "        sheet_name = input(\"Результаты будут импортированы в гугл-таблицу. \\nИмя листа будет: \")\n",
        "        worksheet = experiment_spreadsheet.add_worksheet(title=sheet_name, rows=len(id_array)+1, cols=100)\n",
        "        prepare_googlesheet_for_nd(id_array, source_array, data, name_of_properties, worksheet)\n",
        "      except gspread.exceptions.APIError:\n",
        "        worksheet = experiment_spreadsheet.worksheet(sheet_name)\n",
        "      while True:\n",
        "        print(\"Задать сигму\\n\"\n",
        "              \"Одного единого универсального значения нет!\\n\")\n",
        "        while True:\n",
        "            try:\n",
        "              sigma = float(input(\"Введите сигму: \"))\n",
        "              break\n",
        "            except ValueError:\n",
        "              print(\"Я не знаю таких цифр\")\n",
        "        print(\"Задать скорость обучения\\n\",\n",
        "              \"1. Использовать 3\\n\",\n",
        "              \"2. Задать число самому\\n\")\n",
        "        choice_2 = input(\"Введите опцию: \")\n",
        "        while True:\n",
        "          if choice_2 == '1':\n",
        "            learning_rate = 0.5\n",
        "            break\n",
        "          elif choice_2 == '2':\n",
        "            while True:\n",
        "              try:\n",
        "                learning_rate = int(input(\"Введите минимальное количество точек (Рекомендуется брать от 5 до 2): \"))\n",
        "                break\n",
        "              except ValueError:\n",
        "                print(\"Я не знаю таких цифр\")\n",
        "          else:\n",
        "            print(\"Я не знаю таких цифр\")\n",
        "        #normed_data = to_normalize_except_material(data)\n",
        "        normed_data = to_normalize_except_material(data)\n",
        "        som = MiniSom(1, len(normed_data[:]), len(normed_data[0, :]), sigma=sigma, learning_rate=learning_rate)\n",
        "        som.train_batch(normed_data, 100)\n",
        "        winner_coordinates = np.array([som.winner(x) for x in data]).T\n",
        "        packed_clusters = pack_clusters(data, winner_coordinates[1], 3)\n",
        "        import_result_in_googlesheet_neuro(packed_clusters, worksheet, sigma, learning_rate)\n",
        "        print(f\"Данные в гугл-таблице на листе '{sheet_name}' обновлены!\\n\")\n",
        "        while True:\n",
        "          print(\"Попробовать изменить радиус и/или минамальное количество точек и попробовать снова?\\n\"\n",
        "          \"1. Да\\n\"\n",
        "          \"2. Нет\\n\")\n",
        "          choice_2 = input(\"Введите опцию: \")\n",
        "          if choice_2 == '1':\n",
        "            break\n",
        "          elif choice_2 == '2':\n",
        "            break\n",
        "          else:\n",
        "            print(\"Я не знаю таких цифр\")\n",
        "        if choice_2 == '2':\n",
        "            break\n",
        "    elif choice == 3:\n",
        "      print(\"ДРУГОЙ РЫЧАААГ\")\n",
        "      break\n",
        "    else:\n",
        "      print(\"Я не знаю таких цифр\")\n",
        "  except ValueError:\n",
        "    print(\"Я не знаю таких цифр\")"
      ]
    },
    {
      "source": [
        "weights = som.get_weights()\n",
        "new_aerogel_data = np.array([1, 2, 3, 4, 5])  # Пример данных 71-го аэрогеля\n",
        "normed_new_aerogel_data = to_normalize_except_material(new_aerogel_data)\n",
        "distances = np.linalg.norm(weights - normed_new_aerogel_data, axis=2)\n",
        "winner_neuron = np.argmin(distances)\n",
        "cluster = winner_neuron  # Предполагается, что кластер соответствует индексу нейрона\n",
        "\n",
        "print(f\"71-й аэрогель относится к кластеру {cluster}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "oUTpvJbsxjDU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}