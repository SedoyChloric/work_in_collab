{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SedoyChloric/work_in_collab/blob/test/SVR_QSPR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6saWGgs0h_R6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "\n",
        "gc = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
        "clusterisation_column = 8\n",
        "idk = \"Я не знаю таких цифр\""
      ],
      "metadata": {
        "id": "8x2jgW6vD3Ea"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обработка данных:"
      ],
      "metadata": {
        "id": "T2SR65UfIjPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_clusters(winner_coordinates, learning_rate, sigma, iterations, column, frequency_threshold):\n",
        "  col = calculate_column(column)\n",
        "  title = np.array([[np.round(learning_rate, 4), np.round(sigma, 4), iterations, f'=COUNTUNIQUE({col}6:{col})', f'=\"№\"&столбец({col}1)-7']])\n",
        "  unique_coords, cluster_labels, labels_frequency = np.unique(winner_coordinates, axis=0, return_inverse=True, return_counts=True)\n",
        "  for i, freq in enumerate(labels_frequency):\n",
        "    if freq < frequency_threshold:\n",
        "      cluster_labels[cluster_labels == i] = -1\n",
        "  return np.append(title, [cluster_labels], axis=1)\n",
        "\n",
        "def to_list(array):\n",
        "  return array.reshape(-1, 1).tolist()\n",
        "\n",
        "def to_normalize_except_material(array):\n",
        "  min_val = np.min(array[:, 1:])\n",
        "  max_val = np.max(array[:, 1:])\n",
        "  normed_array = (array[:, 1:] - min_val) / (max_val - min_val)\n",
        "  return np.column_stack((array[:, 0], normed_array))\n",
        "\n",
        "def to_normalize_by_row(array):\n",
        "  normed_array = np.zeros(array.shape)\n",
        "  for i in range(len(array)):\n",
        "    min_val = np.min(array[i])\n",
        "    max_val = np.max(array[i])\n",
        "    normed_array[i] = array[i]\n",
        "    normed_array[i] = (array[i] - min_val) / (max_val - min_val)\n",
        "  return normed_array\n",
        "\n",
        "def trim_table(worksheet, threshold_value, start, end):\n",
        "  unsupervised_data = np.array(worksheet.get_all_values())\n",
        "  data = unsupervised_data[start:end][:].astype('float64')\n",
        "  columns_to_delete = np.zeros(len(data[0]), dtype=bool)\n",
        "  columns_to_delete[data[0] >= threshold_value] = True\n",
        "  columns_to_delete[data[1] >= threshold_value] = True\n",
        "  unsupervised_data = np.delete(unsupervised_data, columns_to_delete, axis=1)\n",
        "  worksheet.clear()\n",
        "  worksheet.update(unsupervised_data.tolist(), f'a1')"
      ],
      "metadata": {
        "id": "jl3R9dDpH9H4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Работа с гугл-таблицами"
      ],
      "metadata": {
        "id": "F6jJ39AOIlsL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_column(number, alphabet=alphabet):\n",
        "  column = ''\n",
        "  while number > 0:\n",
        "    number, remainder = divmod(number - 1, 26)\n",
        "    column = alphabet[remainder] + column\n",
        "  return column\n",
        "\n",
        "def ccell(column, row): #calculatecell\n",
        "  return ''.join([calculate_column(column), str(row)])\n",
        "\n",
        "def get_data_from_googlesheet(google_spreedsheet, sheet_name):\n",
        "  table = np.array(google_spreedsheet.worksheet(sheet_name).get_all_values()) #Лист преобразуется в массив\n",
        "  name_of_properties = table[0][3:-1] # Получаем наименования свойств (со второго до предпоследнего)\n",
        "  table = np.transpose(table) #Транспонируем\n",
        "  id = table[1][1:] #Получаем лист наименований\n",
        "  source = table[-1][1:] #Получаем лист сурсов\n",
        "  properties = table[3:-1][0:] #Получаем лист свойств, который нужно будет снова транспонировать\n",
        "  return id, source, np.transpose(np.delete(properties, 0, 1).astype('float64')), name_of_properties\n",
        "\n",
        "def prepare_googlesheet_for_nd(id_array, source_array, properties_values, name_of_properties, worksheet, row_bias):\n",
        "  worksheet.update(to_list(np.arange(len(id_array)+1)), f'a{row_bias}:a')\n",
        "  worksheet.update(to_list(id_array), f'b{row_bias+1}:b')\n",
        "  worksheet.update([name_of_properties.tolist()], f'c{row_bias}')\n",
        "  worksheet.update(properties_values.tolist(), f'c{row_bias+1}')\n",
        "  worksheet.update_acell(f'b{row_bias}]', \"Наименование точки\")\n",
        "  worksheet.update_acell(f'{calculate_column(len(name_of_properties)+3)}{row_bias}', \"Кластеризация\")\n",
        "  return\n",
        "\n",
        "def prepare_googlesheet_for_1d(id_array, source_array, property_values, name_of_property, worksheet):\n",
        "  worksheet.update(to_list(np.arange(len(id_array)+1)), 'a1:a')\n",
        "  worksheet.update(to_list(id_array), 'b2:b')\n",
        "  worksheet.update(to_list(property_values), 'c2:c')\n",
        "  worksheet.update_acell('b1', name_of_property)\n",
        "  worksheet.update_acell('c1', \"Значение\")\n",
        "  worksheet.update_acell('d1', \"Кластеризация\")\n",
        "  return\n",
        "\n",
        "def prepare_googlesheet_for_starting(worksheet):\n",
        "  array = [[\"Kernel: linear\"], [\"C\"], [\"epsilon\"], [\"gamma\"], [\"MSE\"]]\n",
        "  worksheet.update([[\"Kernel: linear\"], [\"C\"], [\"epsilon\"], [\"gamma\"], [\"MSE\"]], 'a2')\n",
        "  return\n",
        "\n",
        "def import_result_in_googlesheet_neuro(packed_clusters, worksheet, row_bias):\n",
        "  clusterisation = worksheet.find('Кластеризация').col\n",
        "  column = calculate_column(clusterisation)\n",
        "  worksheet.update_acell(f'{calculate_column(clusterisation+len(packed_clusters[0]))}{row_bias}', 'Кластеризация')\n",
        "  worksheet.update(packed_clusters.tolist(), f'{column}{row_bias}', value_input_option='USER_ENTERED')\n",
        "  return\n",
        "\n",
        "def import_result_in_googlesheet_dbscan(packed_clusters, worksheet, radius, minimum_points):\n",
        "  column = worksheet.find('Кластеризация').col\n",
        "  worksheet.update_acell(f'{calculate_column(column)}1', f'R={np.round(radius, 4)}; mp={np.round(minimum_points, 4)}')\n",
        "  worksheet.update_acell(f'{calculate_column(column+1)}1', 'Кластеризация')\n",
        "  worksheet.update(to_list(packed_clusters), f'{calculate_column(column)}2:{calculate_column(column)}')\n",
        "  return"
      ],
      "metadata": {
        "id": "TXz90IwgHuvw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{ccell(2,1)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flIbhypK-WU6",
        "outputId": "055b3839-55d3-4d96-c5f4-71a3ae809d78"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_spreadsheet = gc.open_by_key('199JJj9XfyCkrX9I6I0PKK07vmkfNWT2OPLLX1OSwT8s')\n",
        "experiment_spreadsheet = gc.open_by_key('199JJj9XfyCkrX9I6I0PKK07vmkfNWT2OPLLX1OSwT8s')\n",
        "indices_id_array, source_array, indices, name_of_indices = get_data_from_googlesheet(data_spreadsheet, \"Статья1QSPR\")\n",
        "properties_id_array, source_array, properties, name_of_properties = get_data_from_googlesheet(data_spreadsheet, \"Статья1св-ва\")"
      ],
      "metadata": {
        "id": "uSsFae3ioCmP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  sheet_name = input(\"Результаты будут импортированы в гугл-таблицу. \\nИмя листа будет: \")\n",
        "  worksheet = experiment_spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=1000)\n",
        "  worksheet.update([name_of_indices.tolist()], ccell(2, 1))\n",
        "except gspread.exceptions.APIError:\n",
        "  worksheet = experiment_spreadsheet.worksheet(sheet_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue0LX_Md3eJ3",
        "outputId": "6156f5d7-ba93-44be-ca59-62fb5a77e4d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Результаты будут импортированы в гугл-таблицу. \n",
            "Имя листа будет: Нормированные QSPR и Св-ва 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Основной блок реализации"
      ],
      "metadata": {
        "id": "o5Ap7wtFu6W4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indices_scaler = StandardScaler()\n",
        "properties_scaler = StandardScaler()\n",
        "indices_train, indices_test, properties_train, properties_test = train_test_split(indices, properties, test_size=0.2, shuffle=False)\n",
        "indices_train_scaled = indices_scaler.fit_transform(indices_train)\n",
        "indices_test_scaled =  indices_scaler.transform(indices_test)\n",
        "properties_train_scaled = properties_scaler.fit_transform(properties_train)\n",
        "properties_test_scaled =  properties_scaler.transform(properties_test)\n",
        "indices_train_scaled = indices_train_scaled.T\n",
        "indices_test_scaled = indices_test_scaled.T\n",
        "properties_train_scaled = properties_train_scaled.T\n",
        "properties_test_scaled = properties_test_scaled.T"
      ],
      "metadata": {
        "id": "UMRS6tqg6c5S"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(indices_train_scaled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wvDkIWMqJwg",
        "outputId": "cca7ea25-d56f-4ec9-dd8e-75317f5d3dbe"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svr = SVR()\n",
        "param_grid = {\n",
        "    'kernel': ['linear'],\n",
        "    'C':[0.01, 0.1, 1, 10, 100, 1000],\n",
        "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
        "    'epsilon': [0.01, 0.1, 0.2, 0.5]\n",
        "    }\n",
        "\n",
        "best_params = []\n",
        "best_scores = []\n",
        "trained_svrs = []"
      ],
      "metadata": {
        "id": "mPhmwnyS6m7y"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subrow = 2\n",
        "subcol = 10\n",
        "row = 2\n",
        "column = 2\n",
        "for i in range(properties_train.shape[0]):\n",
        "  print(f\"Training SVR for property {name_of_properties[i]}...\")\n",
        "  title = np.array([[f\"{name_of_properties[i]}\"], [\"C\"], [\"epsilon\"], [\"gamma\"], [\"MSE\"], [\"a0\"], [\"a1\"]])\n",
        "  worksheet.update(title.tolist(), f'{calculate_column(column-1)}{row}')\n",
        "  worksheet.update_acell(f'{calculate_column(subcol)}{subrow}', f'{name_of_properties[i]}')\n",
        "  iteration = np.empty_like(title)\n",
        "  for j in range(indices_train.shape[1]):\n",
        "    print(f\"By molecular indice {name_of_indices[j]}...\")\n",
        "    grid_search = GridSearchCV(svr, param_grid, cv=5, scoring='neg_mean_squared_error', verbose=0, n_jobs=-1)\n",
        "    grid_search.fit(indices_train[:, j].reshape(-1, 1), properties_train[:, i])\n",
        "    subiteration = np.array([[\"X\"]])\n",
        "    subiteration = np.append(subiteration, np.array(list(grid_search.best_params_.values())[0:3]).reshape(-1, 1), axis=0)\n",
        "    subiteration = np.append(subiteration, [[np.round(grid_search.best_score_, 4)]], axis=0)\n",
        "    subiteration = np.append(subiteration, np.round(np.array([grid_search.best_estimator_.intercept_]), 6), axis=0)\n",
        "    subiteration = np.append(subiteration, np.round(grid_search.best_estimator_.coef_, 6), axis=0)\n",
        "    iteration = np.hstack((iteration, subiteration))\n",
        "  iteration = np.delete(iteration, 0, axis=1)\n",
        "  worksheet.update_acell(f'{calculate_column(subcol+1)}{subrow}', f'=ИНДЕКС(b1:i1, Поискпоз(макс({calculate_column(column)}{row+4}:{calculate_column(column+iteration.shape[1]-1)}{row+4}), {calculate_column(column)}{row+4}:{calculate_column(column+iteration.shape[1]-1)}{row+4}, 0))')\n",
        "  subrow += 1\n",
        "  worksheet.update(iteration.tolist(), f'{calculate_column(column)}{row}', value_input_option='USER_ENTERED')\n",
        "  row += title.shape[0]\n"
      ],
      "metadata": {
        "id": "6GAOqJdwu_wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.array((0, 0, 0 ))\n",
        "print(to_list(array))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQsxootWQ1EG",
        "outputId": "b049a957-dc84-46bf-9595-2f5f07d27207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0], [0], [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inverse transform the scaled properties_test and properties_predicted\n",
        "properties_test_original = scaler.inverse_transform(np.hstack((indices_test, properties_test)))[:, indices.shape[1]:]\n",
        "properties_predicted_original = scaler.inverse_transform(np.hstack((indices_test, properties_predicted.reshape(-1, properties_test.shape[1]))))[:, indices.shape[1]:]\n",
        "\n",
        "\n",
        "mse = mean_squared_error(properties_test_original, properties_predicted_original)\n",
        "r2 = r2_score(properties_test_original, properties_predicted_original)\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"R^2: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iwi9giomq8YH",
        "outputId": "17b8a503-49a0-4d3b-f974-441581927953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 20036.3098\n",
            "R^2: -2.3588\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normed_data = to_normalize_except_material(data)\n",
        "column = 8\n",
        "for i in range(2, 6):\n",
        "  learning_rate = i*0.1\n",
        "  for j in range(1, 9):\n",
        "    sigma = j*0.2\n",
        "    packed_clusters = np.zeros((1, len(normed_data)+5))\n",
        "    for k in range(4, 13):\n",
        "      iterations = k*50\n",
        "      som = MiniSom(10, 10, len(normed_data[0]), sigma=sigma, learning_rate=learning_rate)\n",
        "      som.train_batch(normed_data, iterations)\n",
        "      winner_coordinates = np.array([som.winner(x) for x in normed_data])\n",
        "      clusterisation_results = prepare_clusters(winner_coordinates, learning_rate, sigma, iterations, column, 3)\n",
        "      packed_clusters = np.append(packed_clusters, clusterisation_results, axis=0)\n",
        "      column +=1\n",
        "    packed_clusters = np.delete(packed_clusters, 0, axis=0)\n",
        "    import_result_in_googlesheet_neuro(packed_clusters.T, worksheet, 1)\n"
      ],
      "metadata": {
        "id": "JcjbDEdmlffY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column = 8\n",
        "for i in range(1, 4):\n",
        "  learning_rate = i*0.1\n",
        "  for j in range(1, 4):\n",
        "    sigma = j*0.2\n",
        "    packed_clusters = np.zeros((1, len(normed_data)+5))\n",
        "    for k in range(2, 4):\n",
        "      iterations = k*100\n",
        "      som = MiniSom(10, 10, len(normed_data[0]), sigma=sigma, learning_rate=learning_rate)\n",
        "      som.train_batch(train_data, iterations)\n",
        "      winner_coordinates = np.array([som.winner(x) for x in train_data_spec])\n",
        "      winner_coordinates = np.append(winner_coordinates, np.array([som.winner(x) for x in test_data]), axis=0)\n",
        "      clusterisation_results = prepare_clusters(winner_coordinates, learning_rate, sigma, iterations, column, 0)\n",
        "      packed_clusters = np.append(packed_clusters, clusterisation_results, axis=0)\n",
        "      column +=1\n",
        "    packed_clusters = np.delete(packed_clusters, 0, axis=0)\n",
        "    import_result_in_googlesheet_neuro(packed_clusters.T, worksheet, 1)\n"
      ],
      "metadata": {
        "id": "rvY9Pivw6Gu9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "7d3dea1f-4dde-4ba6-e385-95d8cfe08ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (4,) (10,10,5) ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-e32c4ea77515>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0msom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMiniSom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0msom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mwinner_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwinner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data_spec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mwinner_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinner_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwinner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mclusterisation_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinner_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-e32c4ea77515>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0msom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMiniSom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0msom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mwinner_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwinner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_data_spec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mwinner_coordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinner_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwinner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mclusterisation_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_clusters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwinner_coordinates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/minisom.py\u001b[0m in \u001b[0;36mwinner\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwinner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;34m\"\"\"Computes the coordinates of the winning neuron for the sample x.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         return unravel_index(self._activation_map.argmin(),\n\u001b[1;32m    380\u001b[0m                              self._activation_map.shape)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/minisom.py\u001b[0m in \u001b[0;36m_activate\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \"\"\"Updates matrix activation_map, in this matrix\n\u001b[1;32m    279\u001b[0m            the element i,j is the response of the neuron i,j to x.\"\"\"\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activation_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_activation_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mactivate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/minisom.py\u001b[0m in \u001b[0;36m_euclidean_distance\u001b[0;34m(self, x, w)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_euclidean_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_manhattan_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,) (10,10,5) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "AuuyBy30sN1w",
        "outputId": "f7d07741-7d3a-4730-a555-27ee6c4febcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Есть на просторах интернета одна гугл-таблица, в которой собрано немного про характеристики аэрогелей.\n",
            "В этой прекрасной гугл-таблице насчитываются характеристики уже 82 аэрогелей\n",
            "Эта программа может разбивать аэрогели на группы при помощи магии, которая зовётся MiniSOM\n",
            "Магия работает по таким характеристикам, как ['Природа' 'Каж. плотность (г/см^3)' 'Уд, поверхность (м^2/г)'\n",
            " 'Диаметр пор (нм)' 'Пористость (%)']\n",
            "1. Кронк, жми на рычаг просмотра данных!\n",
            "2. Кронк, жми на рычаг кластеризации!\n",
            "3. Кронк, жми на рычаг в лабораторию!\n",
            "Нажмите на рычаг: test6\n",
            "Я не знаю таких цифр\n",
            "1. Кронк, жми на рычаг просмотра данных!\n",
            "2. Кронк, жми на рычаг кластеризации!\n",
            "3. Кронк, жми на рычаг в лабораторию!\n",
            "Нажмите на рычаг: 2\n",
            "Результаты будут импортированы в гугл-таблицу. \n",
            "Имя листа будет: test6\n",
            "Задать сигму\n",
            "Одного единого универсального значения нет!\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-2dae62d07dc4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m               \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Введите сигму: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m               \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "print(\"Есть на просторах интернета одна гугл-таблица, в которой собрано немного про характеристики аэрогелей.\\n\"\n",
        "  \"В этой прекрасной гугл-таблице насчитываются характеристики уже\", len(id_array), \"аэрогелей\\n\"\n",
        "  \"Эта программа может разбивать аэрогели на группы при помощи магии, которая зовётся MiniSOM\\n\"\n",
        "  \"Магия работает по таким характеристикам, как\", name_of_properties)\n",
        "while True:\n",
        "  print(\"1. Кронк, жми на рычаг просмотра данных!\"\n",
        "  \"\\n2. Кронк, жми на рычаг кластеризации!\"\n",
        "  \"\\n3. Кронк, жми на рычаг в лабораторию!\")\n",
        "  try:\n",
        "    choice = int(input(\"Нажмите на рычаг: \"))\n",
        "    if choice == 1:\n",
        "      for i in range(len(id_array)-1):\n",
        "        print(\"Точка\", id_array[i], \"с координатами:\\n\", data[i])\n",
        "    elif choice == 2:\n",
        "      try:\n",
        "        sheet_name = input(\"Результаты будут импортированы в гугл-таблицу. \\nИмя листа будет: \")\n",
        "        worksheet = experiment_spreadsheet.add_worksheet(title=sheet_name, rows=len(id_array)+5, cols=2000)\n",
        "        prepare_googlesheet_for_nd(id_array, source_array, data, name_of_properties, worksheet)\n",
        "      except gspread.exceptions.APIError:\n",
        "        worksheet = experiment_spreadsheet.worksheet(sheet_name)\n",
        "      while True:\n",
        "        print(\"Задать сигму\\n\"\n",
        "              \"Одного единого универсального значения нет!\\n\")\n",
        "        while True:\n",
        "            try:\n",
        "              sigma = float(input(\"Введите сигму: \"))\n",
        "              break\n",
        "            except ValueError:\n",
        "              print(idk)\n",
        "        print(\"Задать скорость обучения\\n\",\n",
        "              \"1. Использовать 3\\n\",\n",
        "              \"2. Задать число самому\\n\")\n",
        "        choice_2 = input(\"Введите опцию: \")\n",
        "        while True:\n",
        "          if choice_2 == '1':\n",
        "            learning_rate = 0.5\n",
        "            break\n",
        "          elif choice_2 == '2':\n",
        "            while True:\n",
        "              try:\n",
        "                learning_rate = int(input(\"Введите минимальное количество точек (Рекомендуется брать от 5 до 2): \"))\n",
        "                break\n",
        "              except ValueError:\n",
        "                print(idk)\n",
        "          else:\n",
        "            print(idk)\n",
        "        #normed_data = to_normalize_except_material(data)\n",
        "        normed_data = to_normalize_except_material(data)\n",
        "        som = MiniSom(1, len(normed_data[:]), len(normed_data[0, :]), sigma=sigma, learning_rate=learning_rate)\n",
        "        som.train_batch(normed_data, 100)\n",
        "        winner_coordinates = np.array([som.winner(x) for x in data]).T\n",
        "        packed_clusters = pack_clusters(data, winner_coordinates[1], 3)\n",
        "        import_result_in_googlesheet_neuro(packed_clusters, worksheet, sigma, learning_rate)\n",
        "        print(f\"Данные в гугл-таблице на листе '{sheet_name}' обновлены!\\n\")\n",
        "        while True:\n",
        "          print(\"Попробовать изменить радиус и/или минамальное количество точек и попробовать снова?\\n\"\n",
        "          \"1. Да\\n\"\n",
        "          \"2. Нет\\n\")\n",
        "          choice_2 = input(\"Введите опцию: \")\n",
        "          if choice_2 == '1':\n",
        "            break\n",
        "          elif choice_2 == '2':\n",
        "            break\n",
        "          else:\n",
        "            print(idk)\n",
        "        if choice_2 == '2':\n",
        "            break\n",
        "    elif choice == 3:\n",
        "      print(\"ДРУГОЙ РЫЧАААГ\")\n",
        "      break\n",
        "    else:\n",
        "      print(idk)\n",
        "  except ValueError:\n",
        "    print(idk)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}